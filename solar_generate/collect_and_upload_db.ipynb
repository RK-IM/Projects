{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import psycopg2\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Climate data using OPEN API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"OPENAPI KEY\"\n",
    "start_date = 20170101\n",
    "end_date = 20181231\n",
    "data_size = 2*365\n",
    "std_id = 159 # 부산\n",
    "url17_18 = f\"http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey={key}&numOfRows={data_size}&pageNo=1&dataCd=ASOS&dateCd=DAY&startDt={start_date}&endDt={end_date}&stnIds={std_id}&dataType=JSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = 20190101\n",
    "end_date = 20201231\n",
    "data_size = 2*365\n",
    "url19_20 = f\"http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey={key}&numOfRows={data_size}&pageNo=1&dataCd=ASOS&dateCd=DAY&startDt={start_date}&endDt={end_date}&stnIds={std_id}&dataType=JSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = 20210101\n",
    "end_date = 20211231\n",
    "data_size = 365\n",
    "url21 = f\"http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey={key}&numOfRows={data_size}&pageNo=1&dataCd=ASOS&dateCd=DAY&startDt={start_date}&endDt={end_date}&stnIds={std_id}&dataType=JSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_17_18 = requests.get(url17_18)\n",
    "raw_data_19_20 = requests.get(url19_20)\n",
    "raw_data_21 = requests.get(url21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_17_18 = json.loads(raw_data_17_18.text)['response']['body']['items']['item']\n",
    "data_19_20 = json.loads(raw_data_19_20.text)['response']['body']['items']['item']\n",
    "data_21 = json.loads(raw_data_21.text)['response']['body']['items']['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "dataset.extend(data_17_18)\n",
    "dataset.extend(data_19_20)\n",
    "dataset.extend(data_21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# with open('dataset.txt', 'w') as f:\n",
    "    # for item in dataset:\n",
    "    #     f.write(f\"{item}\\n\")\n",
    "    # print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt', 'r') as f:\n",
    "    dataset = f.readlines()\n",
    "dataset = [data.strip().replace(\"'\", \"\\\"\") for data in dataset]\n",
    "json_data = [json.loads(data) for data in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data to Cloud (MongoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = 'MongoDB_HOST'\n",
    "USER = 'MongoDB_USER'\n",
    "PASSWORD = 'MongoDB_PASSWORD'\n",
    "DATABASE_NAME = 'project'\n",
    "COLLECTION_NAME = 'busan_climate'\n",
    "MONGO_URI = f\"mongodb+srv://{USER}:{PASSWORD}@{HOST}/{DATABASE_NAME}?retryWrites=true&w=majority\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGO_URI)\n",
    "database = client[DATABASE_NAME]\n",
    "collection = database[COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fb1905a6e50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection.insert_many(documents=json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract solar-related field, save in local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = collection.find({}, {\n",
    "    '_id': 0,\n",
    "    'tm': 1,\n",
    "    'sumSsHr': 1,\n",
    "    'sumGsr': 1,\n",
    "    'hr1MaxIcsr': 1,\n",
    "    'avgTa': 1,\n",
    "    'avgPa': 1,\n",
    "    'avgPs': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download PostgreSQL from docker\n",
    "# Create yaml file, run `docker-compose up` in terminal\n",
    "conn = psycopg2.connect(\n",
    "    dbname='busan_climate', \n",
    "    user='postgres', \n",
    "    password='1234',\n",
    "    host='localhost'\n",
    ")\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"DROP TABLE IF EXISTS solar\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE solar(\n",
    "    Id INTEGER PRIMARY KEY,\n",
    "    Date TEXT,\n",
    "    sumSsHr REAL,\n",
    "    sumGsr REAL,\n",
    "    hr1MaxIcsr REAL,\n",
    "    avgTa REAL, \n",
    "    avgPa REAL,\n",
    "    avgPs REAL\n",
    ")\"\"\")\n",
    "\n",
    "cur.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(datas):\n",
    "    # try:\n",
    "    cur.execute(\"\"\"INSERT INTO solar \n",
    "        VALUES (%s, %s, \n",
    "            NULLIF(%s, '')::REAL, NULLIF(%s, '')::REAL, NULLIF(%s, '')::REAL,\n",
    "            %s, %s, %s)\"\"\",\n",
    "        (i, data['tm'], data['sumSsHr'], data['sumGsr'], data['hr1MaxIcsr'],\n",
    "        data['avgTa'], data['avgPa'], data['avgPs']))\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "cur.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"DROP TABLE IF EXISTS usage\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE usage (\n",
    "    use_kWh INTEGER,\n",
    "    pay INTEGER\n",
    ")\"\"\")\n",
    "\n",
    "cur.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILEPATH =  os.path.join(os.getcwd(), 'payment_by_use.csv')\n",
    "cur.copy_expert(\"\"\"COPY usage FROM STDIN DELIMITER ',' CSV HEADER\"\"\",\n",
    "    open(CSV_FILEPATH, 'r'))\n",
    "\n",
    "cur.execute(\"\"\"ALTER TABLE usage ADD COLUMN reduced_pay REAL\"\"\")\n",
    "cur.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Application.flask_app import payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "november = 275.63\n",
    "month = 11\n",
    "\n",
    "for i in range(1, 1001):\n",
    "    power_fin = i - november\n",
    "    pay = payment.calc_payment(month, power_fin)\n",
    "    if pay <= 1150:\n",
    "        pay = 1150\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    cur.execute(\"\"\"UPDATE usage \n",
    "                   SET reduced_pay = %s \n",
    "                   WHERE use_kwh = %s\"\"\", (pay, i))\n",
    "\n",
    "cur.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to ElephantSQL for Metabase deployment by Heroku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = collection.find({}, {\n",
    "    '_id': 0,\n",
    "    'tm': 1,\n",
    "    'sumSsHr': 1,\n",
    "    'sumGsr': 1,\n",
    "    'hr1MaxIcsr': 1,\n",
    "    'avgTa': 1,\n",
    "    'avgPa': 1,\n",
    "    'avgPs': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from Application.flask_app import payment\n",
    "\n",
    "host = 'ElephantSQL_HOST'\n",
    "user = 'ElephantSQL_USER'\n",
    "password = 'ElephantSQL_PASSWORD'\n",
    "database = 'ElephantSQL_DB'\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Copy table from Docker PostgreSQL, \n",
    "# \\copy table_name to '/file/path/filename.csv' WITH DELIMITER ',' CSV HEADER\n",
    "\n",
    "# Create solar table\n",
    "cur.execute(\"\"\"DROP TABLE IF EXISTS solar\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE solar(\n",
    "    Id INTEGER PRIMARY KEY,\n",
    "    Date TEXT,\n",
    "    sumSsHr REAL,\n",
    "    sumGsr REAL,\n",
    "    hr1MaxIcsr REAL,\n",
    "    avgTa REAL, \n",
    "    avgPa REAL,\n",
    "    avgPs REAL\n",
    ")\"\"\")\n",
    "\n",
    "cur.execute(\"COMMIT\")\n",
    "\n",
    "# Add data\n",
    "CSV_FILEPATH =  os.path.join(os.getcwd(), 'solar.csv')\n",
    "cur.copy_expert(\"\"\"COPY solar FROM STDIN DELIMITER ',' CSV HEADER\"\"\",\n",
    "    open(CSV_FILEPATH, 'r'))\n",
    "\n",
    "cur.execute(\"COMMIT\")\n",
    "\n",
    "\n",
    "# Create usage table\n",
    "cur.execute(\"\"\"DROP TABLE IF EXISTS usage\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE usage (\n",
    "    use_kWh INTEGER,\n",
    "    pay INTEGER,\n",
    "    reduced_pay INTEGER\n",
    ")\"\"\")\n",
    "\n",
    "cur.execute(\"COMMIT\")\n",
    "\n",
    "# Create and Load usage table\n",
    "CSV_FILEPATH =  os.path.join(os.getcwd(), 'usage.csv')\n",
    "cur.copy_expert(\"\"\"COPY usage FROM STDIN DELIMITER ',' CSV HEADER\"\"\",\n",
    "    open(CSV_FILEPATH, 'r'))\n",
    "\n",
    "cur.execute(\"COMMIT\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('proj3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d63a9e3588d76ead20e6904fd5c770e91cb47c18722ebc26c36cffa8995168d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
